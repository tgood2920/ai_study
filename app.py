import streamlit as st
import os
import pandas as pd
import io
import json
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage, AIMessage

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
st.set_page_config(page_title="RFP ì‚¬ì—…ì •ë³´ ì¶”ì¶œê¸°", page_icon="ğŸ“", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•ˆì „ì„± í™•ë³´)
for key in ["messages", "retriever", "docs", "analysis_done"]:
    if key not in st.session_state:
        st.session_state[key] = [] if key == "messages" else None if key != "analysis_done" else False

st.title("ğŸ“ ì œì•ˆì„œ 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ìƒì„±ê¸°")
st.caption("PDFì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ 1ë²ˆ ì‹œíŠ¸ ì–‘ì‹ì— ë§ì¶° ì—‘ì…€ì„ ìƒì„±í•©ë‹ˆë‹¤.")

# 2. PDF ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_resource
def process_pdf_file(file_path):
    try:
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        splits = text_splitter.split_documents(docs)
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
        return vectorstore.as_retriever(), docs
    except Exception as e:
        return None, str(e)

# 3. ë°ì´í„° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ (ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì› ëª…ì¹­ ë³´ì¡´ ë° ì¶•ì•½ ì§€ì¹¨)
def extract_basic_info(docs):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    context = "\n\n".join([doc.page_content for doc in docs[:15]])
    
    prompt = f"""
    ë„ˆëŠ” ê³µê³µì…ì°° ì „ë¬¸ê°€ì•¼. [RFP ë‚´ìš©]ì—ì„œ ì •ë³´ë¥¼ ì°¾ì•„ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•´.
    
    [ê·œì¹™]:
    1. 'ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì›' ëª…ì¹­ì€ ì ˆëŒ€ ì¤„ì´ì§€ ë§ˆë¼.
    2. ëª¨ë“  ë‚´ìš©ì€ ìµœëŒ€í•œ ê¸€ììˆ˜ë¥¼ ì¤„ì—¬ì„œ ì¶•ì•½í•˜ë¼.
    3. ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´("")ë¡œ ì±„ì›Œë¼.
    
    [JSON í‚¤]:
    ê³µì‹ì‚¬ì—…ëª…, ê³µê³ ë²ˆí˜¸, ìˆ˜ìš”ê¸°ê´€, ì‚¬ì—…ì˜ˆì‚°(VATí¬í•¨), ì‚¬ì—…ê¸°ê°„, ì…ì°°ë°©ì‹, ë‚™ì°°ìê²°ì •ë°©ë²•, ì…ì°°ì°¸ê°€ìê²©, ë‹´ë‹¹ìì •ë³´

    [RFP ë‚´ìš©]:
    {context}
    """
    
    try:
        response = llm.invoke(prompt).content
        clean_json = re.search(r'\{.*\}', response, re.DOTALL).group(0)
        return json.loads(clean_json)
    except:
        return None

# --- UI ì„¹ì…˜ ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    project_name = st.text_input("í”„ë¡œì íŠ¸ ë³„ì¹­", value="RFP_ë¶„ì„")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])
    if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

if uploaded_file:
    if "current_file" not in st.session_state or st.session_state["current_file"] != uploaded_file.name:
        st.session_state.update({"current_file": uploaded_file.name, "messages": [], "analysis_done": False, "retriever": None})
        
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f: f.write(uploaded_file.getbuffer())

    if st.session_state["retriever"] is None:
        with st.spinner("ğŸ“„ PDF ë¶„ì„ ì¤‘..."):
            retriever, result_docs = process_pdf_file(temp_path)
            if retriever:
                st.session_state.update({"retriever": retriever, "docs": result_docs, "analysis_done": True})
                st.session_state["messages"].append(AIMessage(content="ë¶„ì„ ì™„ë£Œ! 1ë²ˆ ì‹œíŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."))
            else: st.error(f"ë¶„ì„ ì‹¤íŒ¨: {result_docs}")

    for msg in st.session_state["messages"]:
        st.chat_message("user" if isinstance(msg, HumanMessage) else "assistant").write(msg.content)

    if st.session_state["analysis_done"]:
        st.divider()
        if st.button("ğŸ“Š 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ì‹œíŠ¸ ìƒì„±"):
            with st.spinner("ì—‘ì…€ ì–‘ì‹ êµ¬ì„± ì¤‘..."):
                data_dict = extract_basic_info(st.session_state["docs"])
                
                if data_dict:
                    # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° 'None' ì²˜ë¦¬ (ì¤‘ìš”!)
                    df = pd.DataFrame(list(data_dict.items()), columns=['êµ¬ë¶„', 'ë‚´ìš©'])
                    df = df.fillna("") # ëª¨ë“  NaN/Noneì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì¹˜í™˜
                    
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False, sheet_name='1. ì‚¬ì—…ê¸°ë³¸ì •ë³´')
                        
                        workbook = writer.book
                        worksheet = writer.sheets['1. ì‚¬ì—…ê¸°ë³¸ì •ë³´']
                        
                        # ìŠ¤íƒ€ì¼ ì„¤ì •
                        header_fmt = workbook.add_format({'bold': True, 'align': 'center', 'bg_color': '#D7E4BC', 'border': 1})
                        content_fmt = workbook.add_format({'valign': 'vcenter', 'border': 1, 'text_wrap': True})
                        
                        # ë°ì´í„° ì“°ê¸° (TypeError ë°©ì§€ë¥¼ ìœ„í•´ ê°•ì œ í˜•ë³€í™˜)
                        for col_num, value in enumerate(df.columns.values):
                            worksheet.write(0, col_num, value, header_fmt)
                        
                        for row_num, row_data in enumerate(df.values):
                            worksheet.write(row_num + 1, 0, str(row_data[0]), content_fmt)
                            worksheet.write(row_num + 1, 1, str(row_data[1]), content_fmt)
                        
                        worksheet.set_column(0, 0, 25)
                        worksheet.set_column(1, 1, 85)

                    st.success("1ë²ˆ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ!")
                    st.table(df)
                    st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"{project_name}_ì‚¬ì—…ê¸°ë³¸ì •ë³´.xlsx")
                else:
                    st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    if user_input := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”."):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(HumanMessage(content=user_input))
        with st.chat_message("assistant"):
            search_res = st.session_state["retriever"].invoke(user_input)
            ctx = "\n".join([d.page_content for d in search_res])
            ans = ChatGoogleGenerativeAI(model="gemini-2.0-flash").invoke(f"ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì› ëª…ì¹­ì„ ì¤€ìˆ˜í•˜ê³  ì¶•ì•½í•´ì„œ ë‹µë³€í•˜ë¼.\në‚´ìš©: {ctx}\nì§ˆë¬¸: {user_input}").content
            st.write(ans); st.session_state["messages"].append(AIMessage(content=ans))