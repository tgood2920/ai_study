import streamlit as st
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage, AIMessage

# ì™¸ë¶€ ëª¨ë“ˆ ë¡œë“œ
from excel_gen import get_basic_info_json, create_basic_info_excel

load_dotenv()
st.set_page_config(page_title="RFP ë¶„ì„ ì‹œìŠ¤í…œ", page_icon="ğŸ“‘", layout="wide")

# ì„¸ì…˜ ì´ˆê¸°í™”
for key in ["messages", "retriever", "docs", "analysis_done"]:
    if key not in st.session_state:
        st.session_state[key] = [] if key == "messages" else None if key != "analysis_done" else False

st.title("ğŸ“‘ RFP ë¶„ì„ ì—”ì§„")

@st.cache_resource
def load_and_analyze_pdf(file_path):
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    splits = text_splitter.split_documents(docs)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    return vectorstore.as_retriever(), docs

# --- ì‚¬ì´ë“œë°” ë° ì—…ë¡œë“œ ---
with st.sidebar:
    st.header("ğŸ“‚ ë¶„ì„ ë„êµ¬")
    project_alias = st.text_input("í”„ë¡œì íŠ¸ ëª…ì¹­", "ì…ì°°_ì‚¬ì—…")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])
    if st.button("ğŸ—‘ï¸ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

if uploaded_file:
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f: f.write(uploaded_file.getbuffer())

    if st.session_state["retriever"] is None:
        with st.spinner("ğŸ“„ PDFë¥¼ ì •ë°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            retriever, docs = load_and_analyze_pdf(temp_path)
            st.session_state.update({"retriever": retriever, "docs": docs, "analysis_done": True})
            st.session_state["messages"].append(AIMessage(content="PDF ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."))

    # ì±„íŒ… UI
    for msg in st.session_state["messages"]:
        st.chat_message("user" if isinstance(msg, HumanMessage) else "assistant").write(msg.content)

    # ì—‘ì…€ ìƒì„± ë¡œì§ (ë¶„ë¦¬ëœ ëª¨ë“ˆ í˜¸ì¶œ)
    if st.session_state["analysis_done"]:
        st.divider()
        if st.button("ğŸ“Š 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ì—‘ì…€ ìƒì„±"):
            with st.spinner("ìŠ¤í† ë¦¬ë³´ë“œ ì–‘ì‹ì— ë§ì¶° êµ¬ì„± ì¤‘..."):
                data_dict = get_basic_info_json(st.session_state["docs"])
                excel_file = create_basic_info_excel(data_dict, project_alias)
                
                if excel_file:
                    st.success("1ë²ˆ ì‹œíŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", excel_file, f"{project_alias}_ì‚¬ì—…ê¸°ë³¸ì •ë³´.xlsx")
                else:
                    st.error("ë°ì´í„° ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # ëŒ€í™” ì²˜ë¦¬
    if user_input := st.chat_input("RFPì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”."):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(HumanMessage(content=user_input))
        with st.chat_message("assistant"):
            search_res = st.session_state["retriever"].invoke(user_input)
            ctx = "\n".join([d.page_content for d in search_res])
            ans = ChatGoogleGenerativeAI(model="gemini-2.0-flash").invoke(
                f"ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì› ëª…ì¹­ì„ ì¤€ìˆ˜í•˜ê³  ì¶•ì•½í•´ì„œ ë‹µë³€í•˜ë¼.\në‚´ìš©: {ctx}\nì§ˆë¬¸: {user_input}"
            ).content
            st.write(ans); st.session_state["messages"].append(AIMessage(content=ans))