import streamlit as st
import pandas as pd
import io
import json
import re
from dotenv import load_dotenv

# ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ í•„ìˆ˜ ì„í¬íŠ¸
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS

# ìƒì„±í•œ ëª¨ë“ˆ ì„í¬íŠ¸
from excel_gen1 import write_sheet1
from excel_gen2 import write_sheet2

load_dotenv()
st.set_page_config(page_title="RFP ë¶„ì„ê¸°", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
for key in ["messages", "retriever", "docs", "analysis_done"]:
    if key not in st.session_state:
        st.session_state[key] = [] if key == "messages" else None if key != "analysis_done" else False

st.title("ğŸ“‘ RFP í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ")

# PDF ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_resource
def process_pdf(file_path):
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    splits = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100).split_documents(docs)
    vectorstore = FAISS.from_documents(splits, GoogleGenerativeAIEmbeddings(model="models/embedding-001"))
    return vectorstore.as_retriever(), docs

# ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜
def get_integrated_data(docs):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    context = "\n\n".join([doc.page_content for doc in docs[:15]]) + \
              "\n\n" + "\n\n".join([doc.page_content for doc in docs[-15:]])
    
    prompt = f"""
    RFPë¥¼ ë¶„ì„í•´ JSONìœ¼ë¡œ ì‘ë‹µí•´. ëª¨ë“  ë‚´ìš©ì€ ìµœëŒ€í•œ ì§§ê²Œ ì¶•ì•½í•´.
    êµ¬ì¡°: {{
        "basic_info": {{
            "basic": {{ "ê³µì‹ì‚¬ì—…ëª…":"", "ê³µê³ ë²ˆí˜¸":"", "ìˆ˜ìš”ê¸°ê´€":"", "ì‚¬ì—…ì˜ˆì‚°":"", "ì‚¬ì—…ê¸°ê°„":"", "ì…ì°°ë°©ì‹":"" }},
            "managers": [ {{ "ì†Œì†":"", "ì„±ëª…":"", "ì—°ë½ì²˜":"", "ì´ë©”ì¼":"" }} ],
            "issues": [ {{ "êµ¬ë¶„":"", "ì£¼ìš”ì‚¬í•­":"", "ë¹„ê³ ":"" }} ],
            "status": [ {{ "ì¼ì":"", "ì£¼ìš”ì‚¬í•­":"", "ë¹„ê³ ":"" }} ]
        }},
        "prep_docs": [ {{ "ìˆœë²ˆ":1, "ì„œë¥˜ëª…":"", "ê·œê²©/ìˆ˜ëŸ‰":"", "ì œì¶œë°©ë²•":"", "ë¹„ê³ ":"" }} ]
    }}
    ë‚´ìš©: {context}
    """
    res = llm.invoke(prompt).content
    match = re.search(r'\{.*\}', res, re.DOTALL)
    return json.loads(match.group(0)) if match else None

# --- UI ì„¹ì…˜ ---
with st.sidebar:
    project_alias = st.text_input("í”„ë¡œì íŠ¸ëª…", "ì…ì°°_ì‚¬ì—…")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f: f.write(uploaded_file.getbuffer())

    if not st.session_state["analysis_done"]:
        with st.spinner("ğŸ“„ PDF ë¶„ì„ ì¤‘..."):
            retriever, docs = process_pdf(temp_path)
            st.session_state.update({"retriever": retriever, "docs": docs, "analysis_done": True})

    if st.session_state["analysis_done"]:
        if st.button("ğŸ“Š í†µí•© ì—‘ì…€ ìƒì„± (1, 2ë²ˆ ì‹œíŠ¸)"):
            with st.spinner("ë°ì´í„° ì¶”ì¶œ ë° ì‹œíŠ¸ êµ¬ì„± ì¤‘..."):
                data = get_integrated_data(st.session_state["docs"])
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    wb = writer.book
                    t_fmt = wb.add_format({'bold': True, 'font_size': 12})
                    h_fmt = wb.add_format({'bold': True, 'align': 'center', 'bg_color': '#F2F2F2', 'border': 1})
                    c_fmt = wb.add_format({'border': 1, 'text_wrap': True, 'valign': 'vcenter'})
                    
                    write_sheet1(wb, data, t_fmt, h_fmt, c_fmt)
                    write_sheet2(wb, data, t_fmt, h_fmt, c_fmt)
                
                st.download_button("ğŸ“¥ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"{project_alias}_ì œì•ˆìš”ì•½.xlsx")