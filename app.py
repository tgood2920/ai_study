import streamlit as st
import os
import pandas as pd
import io
import json
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage, AIMessage

# 1. í™˜ê²½ ì„¤ì • ë° ì´ˆê¸°í™”
load_dotenv()
st.set_page_config(page_title="RFP ë§ˆìŠ¤í„° ë¶„ì„ê¸°", page_icon="ğŸ“‘", layout="wide")

for key in ["messages", "retriever", "docs", "analysis_done"]:
    if key not in st.session_state:
        st.session_state[key] = [] if key == "messages" else None if key != "analysis_done" else False

st.title("ğŸ“‘ RFP í†µí•© ë¶„ì„ ë° ë©€í‹° ì‹œíŠ¸ ì—‘ì…€ ìƒì„±")

# 2. PDF ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_resource
def process_pdf_file(file_path):
    try:
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        splits = text_splitter.split_documents(docs)
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
        return vectorstore.as_retriever(), docs
    except Exception as e:
        return None, str(e)

# 3. ë°ì´í„° ì¶”ì¶œ í•µì‹¬ í•¨ìˆ˜
def extract_data_for_sheets(docs):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    context = "\n\n".join([doc.page_content for doc in docs[:20]]) # í•µì‹¬ 20í˜ì´ì§€ ì°¸ì¡°
    
    # ê³µí†µ ì§€ì¹¨
    base_instruction = "ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì› ëª…ì¹­ì€ ì ˆëŒ€ ì¤„ì´ì§€ ë§ˆë¼. ëª¨ë“  ì„¤ëª…ì€ ìµœëŒ€í•œ ì¶•ì•½í•˜ë¼."

    # ì‹œíŠ¸ 1: ì‚¬ì—…ê¸°ë³¸ì •ë³´
    p1 = f"{base_instruction}\nJSONìœ¼ë¡œ ì‘ë‹µí•˜ë¼. í‚¤: ê³µì‹ì‚¬ì—…ëª…, ìˆ˜ìš”ê¸°ê´€, ì‚¬ì—…ê¸°ê°„, ì‚¬ì—…ì˜ˆì‚°, ì…ì°°ë°©ì‹\në‚´ìš©: {context}"
    res1 = llm.invoke(p1).content
    
    # ì‹œíŠ¸ 5: ì œì•ˆëª©ì°¨
    p5 = f"{base_instruction}\nJSON ë°°ì—´ë¡œ ì‘ë‹µí•˜ë¼. ê° ê°ì²´ í‚¤: ëª©ì°¨, ìš”êµ¬ì‚¬í•­ID, ì‘ì„± ì§€ì¹¨\në‚´ìš©: {context}"
    res5 = llm.invoke(p5).content
    
    return res1, res5

# --- UI ì„¹ì…˜ ---
with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    project_name = st.text_input("í”„ë¡œì íŠ¸ëª…", value="ì‚¬ì—…ëª…ì„ ì…ë ¥í•˜ì„¸ìš”")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    if "current_file" not in st.session_state or st.session_state["current_file"] != uploaded_file.name:
        st.session_state.update({"current_file": uploaded_file.name, "messages": [], "analysis_done": False, "retriever": None})
        
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f: f.write(uploaded_file.getbuffer())

    if st.session_state["retriever"] is None:
        with st.spinner("ğŸ“„ RFP ë¶„ì„ ì¤‘..."):
            retriever, result_docs = process_pdf_file(temp_path)
            if retriever:
                st.session_state.update({"retriever": retriever, "docs": result_docs, "analysis_done": True})
                st.session_state["messages"].append(AIMessage(content="RFP ë¶„ì„ ì™„ë£Œ. ì´ì œ ì—‘ì…€ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."))
            else: st.error(f"ë¶„ì„ ì‹¤íŒ¨: {result_docs}")

    for msg in st.session_state["messages"]:
        st.chat_message("user" if isinstance(msg, HumanMessage) else "assistant").write(msg.content)

    if st.session_state["analysis_done"]:
        st.divider()
        if st.button("ğŸš€ í†µí•© ì œì•ˆ ì—‘ì…€ ìƒì„± (ì‹œíŠ¸ 1, 5)"):
            with st.spinner("AIê°€ ë©€í‹° ì‹œíŠ¸ ë°ì´í„°ë¥¼ êµ¬ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                r1, r5 = extract_data_for_sheets(st.session_state["docs"])
                try:
                    # JSON íŒŒì‹±
                    data1 = json.loads(re.search(r'\{.*\}', r1, re.DOTALL).group(0))
                    data5 = json.loads(re.search(r'\[.*\]', r5, re.DOTALL).group(0))
                    
                    df1 = pd.DataFrame(list(data1.items()), columns=['í•­ëª©', 'ë‚´ìš©'])
                    df5 = pd.DataFrame(data5)
                    
                    # ë©€í‹° ì‹œíŠ¸ ì—‘ì…€ ìƒì„±
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df1.to_excel(writer, index=False, sheet_name='1. ì‚¬ì—…ê¸°ë³¸ì •ë³´')
                        df5.to_excel(writer, index=False, sheet_name='5. ì œì•ˆëª©ì°¨_ë³€ê²½')
                        
                        # ì„œì‹ ì„¤ì • (1ë²ˆ ì‹œíŠ¸)
                        ws1 = writer.sheets['1. ì‚¬ì—…ê¸°ë³¸ì •ë³´']
                        ws1.set_column(0, 0, 25); ws1.set_column(1, 1, 65)
                        
                        # ì„œì‹ ì„¤ì • (5ë²ˆ ì‹œíŠ¸)
                        ws5 = writer.sheets['5. ì œì•ˆëª©ì°¨_ë³€ê²½']
                        ws5.set_column(0, 0, 30); ws5.set_column(1, 1, 20); ws5.set_column(2, 2, 70)

                    st.success("í†µí•© ì—‘ì…€ ìƒì„± ì„±ê³µ!")
                    st.download_button("ğŸ“¥ í†µí•© ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"{project_name}_í†µí•©ì œì•ˆì„œ.xlsx")
                except:
                    st.error("ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    if user_input := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”."):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(HumanMessage(content=user_input))
        with st.chat_message("assistant"):
            search_res = st.session_state["retriever"].invoke(user_input)
            ctx = "\n".join([d.page_content for d in search_res])
            ans = ChatGoogleGenerativeAI(model="gemini-2.0-flash").invoke(f"ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì› ëª…ì¹­ì„ ì¤€ìˆ˜í•˜ê³  ì¶•ì•½í•´ì„œ ë‹µë³€í•˜ë¼.\në‚´ìš©: {ctx}\nì§ˆë¬¸: {user_input}").content
            st.write(ans); st.session_state["messages"].append(AIMessage(content=ans))
else: st.info("PDFë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")