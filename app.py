import streamlit as st
import os
import time
import pandas as pd
import io
import json
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage, AIMessage

# 1. ì´ˆê¸° ì„¤ì •
load_dotenv()
st.set_page_config(page_title="RFP ë¶„ì„ê¸° Pro", page_icon="ğŸ“‘", layout="wide")

if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "analysis_done" not in st.session_state:
    st.session_state["analysis_done"] = False

st.title("ğŸ“‘ RFP ì…ì°° ë¶„ì„ê¸° (ì‚¬ì—…ê¸°ë³¸ì •ë³´ íŠ¹í™”)")

# 2. PDF ì²˜ë¦¬
@st.cache_resource
def process_pdf(file_path):
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    return vectorstore.as_retriever(), docs

# 3. RFP ê¸°ë³¸ ìš”ì•½ ë¶„ì„
def analyze_rfp(docs, project_name):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    context = "\n\n".join([doc.page_content for doc in docs[:10]])
    prompt = f"""ë„ˆëŠ” ê³µê³µì…ì°° ì „ë¬¸ê°€ì•¼. RFPë¥¼ ë¶„ì„í•´ í•µì‹¬ë§Œ ì¶•ì•½í•´ì„œ ë³´ê³ í•´.
    **ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì›** ëª…ì¹­ì„ ì ˆëŒ€ ì¤„ì´ì§€ ë§ˆ.
    ì‚¬ì—…ëª…: {project_name}\në‚´ìš©: {context}
    ê²°ê³¼ í•­ëª©: ## 1. ì‚¬ì—…ê°œìš”, 2. ë¦¬ìŠ¤í¬, 3. í•µì‹¬ ìš”êµ¬ì‚¬í•­"""
    return llm.invoke(prompt).content

# 4. [íŠ¹í™”] 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ë°ì´í„° ì¶”ì¶œ (JSON ë°©ì‹)
def extract_basic_info(docs):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    # ì‚¬ì—… ê°œìš”ê°€ ì§‘ì¤‘ëœ ì•ë¶€ë¶„ 10í˜ì´ì§€ ì°¸ì¡°
    context = "\n\n".join([doc.page_content for doc in docs[:10]])
    
    prompt = f"""RFPì—ì„œ ë‹¤ìŒ ì •ë³´ë¥¼ ì°¾ì•„ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´. 
    **ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í—˜ì›** ëª…ì¹­ì„ ì ˆëŒ€ ì¤„ì´ì§€ ë§ˆ. ëª¨ë“  ì„¤ëª…ì€ ìµœëŒ€í•œ ì¶•ì•½í•´.
    
    í•„ìˆ˜ í•­ëª©: 
    - ê³µì‹ì‚¬ì—…ëª…
    - ìˆ˜ìš”ê¸°ê´€
    - ì‚¬ì—…ê¸°ê°„
    - ì‚¬ì—…ë¹„ìš© (ë¶€ê°€ì„¸ í¬í•¨ ì—¬ë¶€ ëª…ì‹œ)
    - ê³µê³ ì¼
    - ì…ì°°ë°©ì‹
    
    [RFP ë‚´ìš©]: {context}
    
    ì¶œë ¥ í˜•ì‹: {{ "ê³µì‹ì‚¬ì—…ëª…": "...", "ìˆ˜ìš”ê¸°ê´€": "...", "ì‚¬ì—…ê¸°ê°„": "...", "ì‚¬ì—…ë¹„ìš©": "...", "ê³µê³ ì¼": "...", "ì…ì°°ë°©ì‹": "..." }}
    """
    res = llm.invoke(prompt).content
    # JSON ë¬¸ìì—´ë§Œ ì¶”ì¶œ
    match = re.search(r'\{.*\}', res, re.DOTALL)
    return match.group(0) if match else "{}"

# --- UI ì˜ì—­ ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    project_name = st.text_input("í”„ë¡œì íŠ¸ëª…", value="ì‚¬ì—…ëª…ì„ ì…ë ¥í•˜ì„¸ìš”")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    if "last_file" not in st.session_state or st.session_state["last_file"] != uploaded_file.name:
        st.session_state.update({"last_file": uploaded_file.name, "messages": [], "analysis_done": False})
        if "retriever" in st.session_state: del st.session_state["retriever"]

    if "retriever" not in st.session_state:
        with st.spinner("RFP ë¶„ì„ ì¤‘..."):
            retriever, docs = process_pdf(temp_path)
            st.session_state.update({"retriever": retriever, "docs": docs})
            res = analyze_rfp(docs, project_name)
            st.session_state["messages"].append(AIMessage(content=res))
            st.session_state["analysis_done"] = True

    for msg in st.session_state["messages"]:
        st.chat_message("user" if isinstance(msg, HumanMessage) else "assistant").write(msg.content)

    if st.session_state["analysis_done"]:
        st.divider()
        if st.button("ğŸ“ 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ì—‘ì…€ ìƒì„±"):
            with st.spinner("ë°ì´í„° ì¶”ì¶œ ì¤‘..."):
                json_raw = extract_basic_info(st.session_state["docs"])
                try:
                    data_dict = json.loads(json_raw)
                    # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ (í–‰íƒœ: í•­ëª© | ë‚´ìš©)
                    df = pd.DataFrame(list(data_dict.items()), columns=['í•­ëª©', 'ë‚´ìš©'])
                    
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False, sheet_name='1. ì‚¬ì—…ê¸°ë³¸ì •ë³´')
                        ws = writer.sheets['1. ì‚¬ì—…ê¸°ë³¸ì •ë³´']
                        ws.set_column(0, 0, 20)
                        ws.set_column(1, 1, 60)
                    
                    st.success("1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ!")
                    st.table(df) # ê¹”ë”í•œ í‘œë¡œ í‘œì‹œ
                    st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"{project_name}_ì‚¬ì—…ê¸°ë³¸ì •ë³´.xlsx")
                except:
                    st.error("ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    st.write(json_raw)

    if user_input := st.chat_input("RFPì— ëŒ€í•´ ë” ê¶ê¸ˆí•œ ì ì€?"):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(HumanMessage(content=user_input))
        with st.chat_message("assistant"):
            ctx = "\n".join([d.page_content for d in st.session_state["retriever"].invoke(user_input)])
            ans = ChatGoogleGenerativeAI(model="gemini-2.0-flash").invoke(f"RFPë‚´ìš©: {ctx}\nì§ˆë¬¸: {user_input}").content
            st.write(ans)
            st.session_state["messages"].append(AIMessage(content=ans))
else:
    st.info("RFP PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")