import streamlit as st
import os
import time
import pandas as pd
import io
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate

# 1. ì´ˆê¸° ì„¤ì •
load_dotenv()
st.set_page_config(page_title="RFP ë¶„ì„ & ìŠ¤í† ë¦¬ë³´ë“œ", page_icon="ğŸ“‘", layout="wide")

if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "analysis_done" not in st.session_state:
    st.session_state["analysis_done"] = False

st.title("ğŸ“‘ RFP ë¶„ì„ ë° ì œì•ˆ ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±ê¸°")

# 2. PDF ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_resource
def process_pdf(file_path):
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    return vectorstore.as_retriever(), docs

# 3. ê¸°ë³¸ ë¶„ì„ í•¨ìˆ˜ (ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì› ëª…ì¹­ ì¤€ìˆ˜)
def analyze_rfp(docs, project_name):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    context_text = "\n\n".join([doc.page_content for doc in docs[:10]])
    prompt = f"""ë„ˆëŠ” ì „ë¬¸ PMì´ì•¼. ì•„ë˜ RFPë¥¼ ë¶„ì„í•´. 
    ë°˜ë“œì‹œ 'ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì›' ëª…ì¹­ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  ì¤„ì´ì§€ ë§ˆ.
    ì‚¬ì—…ëª…: {project_name}\në‚´ìš©: {context_text}
    ì–‘ì‹: ## 1. ê°œìš”, 2. ë¦¬ìŠ¤í¬(ë…ì†Œì¡°í•­), 3. ì œì•ˆì „ëµ"""
    return llm.invoke(prompt).content

# 4. ìŠ¤í† ë¦¬ë³´ë“œ ë°ì´í„° ìƒì„± (ì‚¬ìš©ì ì—‘ì…€ ì–‘ì‹ ë°˜ì˜)
def generate_storyboard_data(docs, project_name):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.2)
    context_text = "\n\n".join([doc.page_content for doc in docs[:15]])
    
    prompt = f"""ë„ˆëŠ” ì œì•ˆ ê¸°íšìì•¼. RFPë¥¼ í† ëŒ€ë¡œ 'ì œì•ˆëª©ì°¨' ì‹œíŠ¸ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´.
    ì‚¬ì—…ëª…: {project_name}\në‚´ìš©: {context_text}
    
    [ì¶œë ¥ ê·œì¹™]:
    1. ë°˜ë“œì‹œ íŒŒì´í”„(|)ë¡œ êµ¬ë¶„ëœ CSV í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´. ì„¤ëª…ì€ ìƒëµí•´.
    2. ì»¬ëŸ¼ëª…: ëª©ì°¨|ì‘ì„±ì|ìš”êµ¬ì‚¬í•­ID|ì‘ì„± ì§€ì¹¨(í•„ìˆ˜)|í‰ê°€ë°°ì |í‰ê°€ê¸°ì¤€
    3. ëª©ì°¨ëŠ” I.II.1.1.1 ìˆœì„œë¡œ ìƒì„¸íˆ êµ¬ì„±í•´.
    """
    return llm.invoke(prompt).content

# --- UI ì˜ì—­ ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    project_name = st.text_input("ì‚¬ì—…ëª…", value="ì‚¬ì—…ëª…ì„ ì…ë ¥í•˜ì„¸ìš”")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    if "last_file" not in st.session_state or st.session_state["last_file"] != uploaded_file.name:
        st.session_state.update({"last_file": uploaded_file.name, "messages": [], "analysis_done": False})
        if "retriever" in st.session_state: del st.session_state["retriever"]

    if "retriever" not in st.session_state:
        with st.spinner("RFP ë¶„ì„ ì¤‘..."):
            retriever, docs = process_pdf(temp_path)
            st.session_state.update({"retriever": retriever, "docs": docs})
            res = analyze_rfp(docs, project_name)
            st.session_state["messages"].append(AIMessage(content=res))
            st.session_state["analysis_done"] = True

    for msg in st.session_state["messages"]:
        st.chat_message("user" if isinstance(msg, HumanMessage) else "assistant").write(msg.content)

    if st.session_state["analysis_done"]:
        if st.button("ğŸ“Š ì—‘ì…€ ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±"):
            with st.spinner("ì—‘ì…€ íŒŒì¼ êµ¬ì„± ì¤‘..."):
                raw_data = generate_storyboard_data(st.session_state["docs"], project_name)
                try:
                    # ë°ì´í„° í´ë¦¬ë‹: ë¶ˆí•„ìš”í•œ ì„¤ëª… ë° ë§ˆí¬ë‹¤ìš´ ì œê±°
                    clean_data = re.sub(r'^[^{|]*\n', '', raw_data, flags=re.MULTILINE)
                    lines = [l.strip() for l in clean_data.split('\n') if '|' in l]
                    df = pd.read_csv(io.StringIO("\n".join(lines)), sep="|")
                    
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False, sheet_name='5. ì œì•ˆëª©ì°¨_ë³€ê²½')
                        # ì—‘ì…€ ì„œì‹ ìë™ ì§€ì •
                        ws = writer.sheets['5. ì œì•ˆëª©ì°¨_ë³€ê²½']
                        for i, col in enumerate(df.columns):
                            ws.set_column(i, i, 25)
                    
                    st.success("ìƒì„± ì™„ë£Œ!")
                    st.dataframe(df)
                    st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"{project_name}_ìŠ¤í† ë¦¬ë³´ë“œ.xlsx")
                except:
                    st.error("ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨. AIê°€ í˜•ì‹ì„ ì§€í‚¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    st.text_area("AI ì‘ë‹µ ì›ë³¸", raw_data)

    if user_input := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”"):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(HumanMessage(content=user_input))
        with st.chat_message("assistant"):
            ctx = "\n".join([d.page_content for d in st.session_state["retriever"].invoke(user_input)])
            ans = ChatGoogleGenerativeAI(model="gemini-2.0-flash").invoke(f"RFPë‚´ìš©: {ctx}\nì§ˆë¬¸: {user_input}").content
            st.write(ans)
            st.session_state["messages"].append(AIMessage(content=ans))
else:
    st.info("RFP PDFë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")