import streamlit as st
import os
import pandas as pd
import io
import json
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage, AIMessage

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
st.set_page_config(page_title="RFP ì…ì°° ë¶„ì„ê¸° Pro", page_icon="ğŸ“‘", layout="wide")

if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "analysis_done" not in st.session_state:
    st.session_state["analysis_done"] = False

st.title("ğŸ“‘ RFP ë¶„ì„ ë° ì—‘ì…€ ë°ì´í„° ì¶”ì¶œ")

# 2. PDF ì²˜ë¦¬ ë¡œì§
@st.cache_resource
def process_pdf(file_path):
    try:
        loader = PyPDFLoader(file_path)
        docs = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
        return vectorstore.as_retriever(), docs
    except Exception as e:
        st.error(f"PDF ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

# 3. [í•µì‹¬] 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜
def extract_basic_info_secure(docs):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    # ì‚¬ì—… ê°œìš”ê°€ ì§‘ì¤‘ëœ ì•ë¶€ë¶„ 15í˜ì´ì§€ ì°¸ì¡°
    context = "\n\n".join([doc.page_content for doc in docs[:15]])
    
    prompt = f"""
    ë„ˆëŠ” ê³µê³µê¸°ê´€ ì…ì°° ë°ì´í„° ë¶„ì„ê°€ì•¼. ì•„ë˜ [RFP ë‚´ìš©]ì—ì„œ ì •ë³´ë¥¼ ì°¾ì•„ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´.
    
    [ì¤€ìˆ˜ ì‚¬í•­]:
    1. 'ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì›'ì€ ì ˆëŒ€ ì¤„ì´ì§€ ë§ê³  ì „ì²´ ëª…ì¹­ì„ ì‚¬ìš©í•´.
    2. ë‚˜ë¨¸ì§€ ëª¨ë“  ì •ë³´ëŠ” ìµœëŒ€í•œ ê°„ê²°í•˜ê²Œ ì¶•ì•½í•´ì„œ ì‘ì„±í•´.
    3. JSON ë°ì´í„° ì™¸ì— ì–´ë–¤ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ë„ í¬í•¨í•˜ì§€ ë§ˆ.

    [JSON í‚¤ê°’]:
    - ê³µì‹ì‚¬ì—…ëª…
    - ìˆ˜ìš”ê¸°ê´€
    - ì‚¬ì—…ê¸°ê°„
    - ì‚¬ì—…ì˜ˆì‚°(VATí¬í•¨)
    - ê³µê³ ì¼
    - ì…ì°°ë°©ì‹

    [RFP ë‚´ìš©]:
    {context}
    """
    
    response = llm.invoke(prompt).content
    
    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ JSON ë°ì´í„°ë§Œ ì¶”ì¶œ (ê°•ë ¥í•œ í•„í„°ë§)
    try:
        # ì¤‘ê´„í˜¸ ì‚¬ì´ì˜ ë‚´ìš©ì„ ì°¾ìŒ
        match = re.search(r'\{.*\}', response, re.DOTALL)
        if match:
            json_str = match.group(0)
            return json.loads(json_str), response
        return None, response
    except Exception as e:
        return None, str(e)

# --- UI ì˜ì—­ ---
with st.sidebar:
    st.header("âš™ï¸ í”„ë¡œì íŠ¸ ì„¤ì •")
    project_name = st.text_input("í”„ë¡œì íŠ¸ëª…", value="ì…ë ¥í•´ì£¼ì„¸ìš”")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # íŒŒì¼ ë³€ê²½ ì‹œ ì´ˆê¸°í™”
    if "last_file" not in st.session_state or st.session_state["last_file"] != uploaded_file.name:
        st.session_state.update({"last_file": uploaded_file.name, "messages": [], "analysis_done": False})
        if "retriever" in st.session_state: del st.session_state["retriever"]

    if "retriever" not in st.session_state:
        with st.spinner("RFP ë°ì´í„°ë¥¼ ì •ë°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            retriever, docs = process_pdf(temp_path)
            if retriever:
                st.session_state.update({"retriever": retriever, "docs": docs})
                st.session_state["analysis_done"] = True
                st.session_state["messages"].append(AIMessage(content="ë¶„ì„ì´ ëë‚¬ìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ 1ë²ˆ ì‹œíŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”."))

    # ì±„íŒ…ì°½ í‘œì‹œ
    for msg in st.session_state["messages"]:
        st.chat_message("user" if isinstance(msg, HumanMessage) else "assistant").write(msg.content)

    # ì—‘ì…€ ìƒì„± ì˜ì—­
    if st.session_state["analysis_done"]:
        st.divider()
        if st.button("ğŸ“ 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ì—‘ì…€ ìƒì„±"):
            with st.spinner("ì—‘ì…€ ë°ì´í„°ë¥¼ êµ¬ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                data_dict, raw_res = extract_basic_info_secure(st.session_state["docs"])
                
                if data_dict:
                    df = pd.DataFrame(list(data_dict.items()), columns=['í•­ëª©', 'ë‚´ìš©'])
                    
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False, sheet_name='1. ì‚¬ì—…ê¸°ë³¸ì •ë³´')
                        ws = writer.sheets['1. ì‚¬ì—…ê¸°ë³¸ì •ë³´']
                        # í—¤ë” ìŠ¤íƒ€ì¼ë§
                        fmt = writer.book.add_format({'bold': True, 'bg_color': '#D7E4BC', 'border': 1})
                        for col_num, value in enumerate(df.columns.values):
                            ws.write(0, col_num, value, fmt)
                        ws.set_column(0, 0, 20)
                        ws.set_column(1, 1, 60)
                    
                    st.success("ë°ì´í„° ì¶”ì¶œ ë° ì—‘ì…€ êµ¬ì„± ì™„ë£Œ!")
                    st.table(df) # ë¯¸ë¦¬ë³´ê¸°
                    st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"{project_name}_ê¸°ë³¸ì •ë³´.xlsx")
                else:
                    st.error("ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨. AI ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
                    with st.expander("ë””ë²„ê¹… ì •ë³´ (AI ì‘ë‹µ ì›ë³¸)"):
                        st.code(raw_res)

    # Q&A ì²˜ë¦¬
    if user_input := st.chat_input("RFPì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”."):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(HumanMessage(content=user_input))
        with st.chat_message("assistant"):
            ctx = "\n".join([d.page_content for d in st.session_state["retriever"].invoke(user_input)])
            ans = ChatGoogleGenerativeAI(model="gemini-2.0-flash").invoke(f"RFPë‚´ìš©: {ctx}\nì§ˆë¬¸: {user_input}").content
            st.write(ans)
            st.session_state["messages"].append(AIMessage(content=ans))
else:
    st.info("RFP PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")