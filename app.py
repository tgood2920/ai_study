import streamlit as st
import os
import time
import pandas as pd
import io
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate

# 1. ì´ˆê¸° ì„¤ì • ë° ë³´ì•ˆ
load_dotenv()
st.set_page_config(page_title="RFP ë¶„ì„ê¸° Pro", page_icon="ğŸ“‘", layout="wide")

if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "analysis_done" not in st.session_state:
    st.session_state["analysis_done"] = False

# ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì› ëª…ì¹­ ì¤€ìˆ˜ ì•ˆë‚´
st.title("ğŸ“‘ RFP ì…ì°° ë¶„ì„ ë° ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±ê¸°")

# 2. PDF ì²˜ë¦¬ ë¡œì§
@st.cache_resource
def process_pdf(file_path):
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    return vectorstore.as_retriever(), docs

# 3. RFP ë¶„ì„ í•¨ìˆ˜
def analyze_rfp(docs, project_name):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    context = "\n\n".join([doc.page_content for doc in docs[:10]])
    prompt = f"""ë„ˆëŠ” ê³µê³µì…ì°° PMì´ì•¼. ì•„ë˜ RFPë¥¼ ë¶„ì„í•´. 
    **ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì›** ëª…ì¹­ì„ ì ˆëŒ€ ì¤„ì—¬ ì“°ì§€ ë§ˆ.
    ì‚¬ì—…ëª…: {project_name}\në‚´ìš©: {context}
    ê²°ê³¼ í•­ëª©: ## 1. ì‚¬ì—…ê°œìš”, 2. ë¦¬ìŠ¤í¬/ë…ì†Œì¡°í•­, 3. ìˆ˜ì£¼ ì „ëµ"""
    return llm.invoke(prompt).content

# 4. ìŠ¤í† ë¦¬ë³´ë“œ ë°ì´í„° ìƒì„± (ì‚¬ìš©ì ì—‘ì…€ ì–‘ì‹ ë™ê¸°í™”)
def generate_storyboard_data(docs, project_name):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.2)
    context = "\n\n".join([doc.page_content for doc in docs[:20]])
    
    prompt = f"""ë„ˆëŠ” ì œì•ˆì„œ ê¸°íšìì•¼. RFPë¥¼ ë¶„ì„í•´ 'ì œì•ˆëª©ì°¨' ë°ì´í„°ë¥¼ ìƒì„±í•´.
    **ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì›** ëª…ì¹­ì„ ì¤€ìˆ˜í•´.
    
    [ì¶œë ¥ ê·œì¹™]:
    1. ë°˜ë“œì‹œ íŒŒì´í”„(|) êµ¬ë¶„ìë¥¼ ì‚¬ìš©í•œ CSV í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´.
    2. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```)ì´ë‚˜ ì„¤ëª…ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.
    3. í—¤ë”ëª…: ëª©ì°¨|ì‘ì„±ì|ìš”êµ¬ì‚¬í•­ID|ì‘ì„± ì§€ì¹¨(í•„ìˆ˜)|í‰ê°€ë°°ì |í‰ê°€ê¸°ì¤€
    
    ì‚¬ì—…ëª…: {project_name}\në‚´ìš©: {context}"""
    return llm.invoke(prompt).content

# --- UI ì˜ì—­ ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    project_name = st.text_input("ì‚¬ì—…ëª…", value="ì…ë ¥í•´ì£¼ì„¸ìš”")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    if "last_file" not in st.session_state or st.session_state["last_file"] != uploaded_file.name:
        st.session_state.update({"last_file": uploaded_file.name, "messages": [], "analysis_done": False})
        if "retriever" in st.session_state: del st.session_state["retriever"]

    if "retriever" not in st.session_state:
        with st.spinner("RFP ë¶„ì„ ì¤‘..."):
            retriever, docs = process_pdf(temp_path)
            st.session_state.update({"retriever": retriever, "docs": docs})
            res = analyze_rfp(docs, project_name)
            st.session_state["messages"].append(AIMessage(content=res))
            st.session_state["analysis_done"] = True

    for msg in st.session_state["messages"]:
        st.chat_message("user" if isinstance(msg, HumanMessage) else "assistant").write(msg.content)

    if st.session_state["analysis_done"]:
        if st.button("ğŸ“Š ì—‘ì…€ ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„±"):
            with st.spinner("ì—‘ì…€ ì‹œíŠ¸ êµ¬ì„± ì¤‘..."):
                raw = generate_storyboard_data(st.session_state["docs"], project_name)
                try:
                    # ë°ì´í„° ì •ì œ ë¡œì§ ê°•í™”: ë§ˆí¬ë‹¤ìš´ ë° ì„œìˆ ë¬¸ ì œê±°
                    clean = re.sub(r'```(?:csv|text)?|```', '', raw).strip()
                    lines = [l for l in clean.split('\n') if '|' in l]
                    
                    df = pd.read_csv(io.StringIO("\n".join(lines)), sep="|")
                    
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False, sheet_name='5. ì œì•ˆëª©ì°¨_ë³€ê²½')
                        ws = writer.sheets['5. ì œì•ˆëª©ì°¨_ë³€ê²½']
                        for i, col in enumerate(df.columns):
                            ws.set_column(i, i, 25) # ì—´ ë„ˆë¹„ ì¡°ì •
                    
                    st.success("ìŠ¤í† ë¦¬ë³´ë“œ ìƒì„± ì™„ë£Œ!")
                    st.dataframe(df)
                    st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", output.getvalue(), f"{project_name}_ìŠ¤í† ë¦¬ë³´ë“œ.xlsx")
                except Exception as e:
                    st.error("íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ. AIì˜ ì‘ë‹µ í˜•ì‹ì´ ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    st.text_area("ì›ë³¸ ì‘ë‹µ(ë””ë²„ê¹…ìš©)", raw)

    if user_input := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš”"):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(HumanMessage(content=user_input))
        with st.chat_message("assistant"):
            ctx = "\n".join([d.page_content for d in st.session_state["retriever"].invoke(user_input)])
            ans = ChatGoogleGenerativeAI(model="gemini-2.0-flash").invoke(f"RFPë‚´ìš©: {ctx}\nì§ˆë¬¸: {user_input}").content
            st.write(ans)
            st.session_state["messages"].append(AIMessage(content=ans))
else:
    st.info("ì™¼ìª½ì—ì„œ RFP PDFë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")