import streamlit as st
import os
import pandas as pd
import io
import json
import re
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_core.messages import HumanMessage, AIMessage

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
st.set_page_config(page_title="RFP ì…ì°° ë¶„ì„ê¸°", page_icon="ğŸ“‘", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []
if "analysis_done" not in st.session_state:
    st.session_state["analysis_done"] = False

st.title("ğŸ“‘ RFP ë¶„ì„ ë° ì‚¬ì—…ê¸°ë³¸ì •ë³´ ì¶”ì¶œ")

# 2. PDF ì²˜ë¦¬ ë¡œì§
@st.cache_resource
def process_pdf(file_path):
    loader = PyPDFLoader(file_path)
    docs = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    return vectorstore.as_retriever(), docs

# 
# 3. [íŠ¹í™”] 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜
def extract_basic_info_json(docs):
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.1)
    # ì‚¬ì—… ê°œìš”ê°€ ì§‘ì¤‘ëœ ì•ë¶€ë¶„ ì°¸ì¡°
    context = "\n\n".join([doc.page_content for doc in docs[:10]])
    
    prompt = f"""
    ë„ˆëŠ” ê³µê³µì…ì°° ë°ì´í„° ì¶”ì¶œ ì „ë¬¸ê°€ì•¼. ì•„ë˜ RFP ë‚´ìš©ì„ ë¶„ì„í•´ì„œ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´.
    
    [í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­]:
    1. 'ì¤‘ì†Œê¸°ì—…ê¸°ìˆ ì •ë³´ì§„í¥ì›' ëª…ì¹­ì€ ì ˆëŒ€ ì¤„ì´ì§€ ë§ê³  ì „ì²´ ì´ë¦„ì„ ì‚¬ìš©í•´.
    2. ë‚˜ë¨¸ì§€ ëª¨ë“  ì„¤ëª…ê³¼ ë‚´ìš©ì€ ìµœëŒ€í•œ ê°„ê²°í•˜ê²Œ ì¶•ì•½í•´ì„œ í‘œí˜„í•´.
    3. JSON ì™¸ì˜ ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.

    [ì¶”ì¶œ í•­ëª©]:
    - ê³µì‹ì‚¬ì—…ëª…
    - ìˆ˜ìš”ê¸°ê´€
    - ì‚¬ì—…ê¸°ê°„
    - ì‚¬ì—…ì˜ˆì‚°(ë¶€ê°€ì„¸í¬í•¨)
    - ê³µê³ ì¼
    - ì…ì°°ë°©ì‹(ê³„ì•½ë°©ë²•)

    [RFP ë‚´ìš©]:
    {context}
    """
    
    response = llm.invoke(prompt).content
    
    # JSON íŒŒì‹±ì„ ìœ„í•œ ì •ê·œí‘œí˜„ì‹ (ì¤‘ê´„í˜¸ ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ)
    try:
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(0))
        return None
    except:
        return None

# --- UI ì˜ì—­ ---
with st.sidebar:
    st.header("âš™ï¸ í”„ë¡œì íŠ¸ ì„¤ì •")
    project_name = st.text_input("í”„ë¡œì íŠ¸ëª…", value="ì‚¬ì—…ëª…ì„ ì…ë ¥í•˜ì„¸ìš”")
    uploaded_file = st.file_uploader("RFP PDF ì—…ë¡œë“œ", type=["pdf"])

if uploaded_file:
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # íŒŒì¼ êµì²´ ì‹œ ì´ˆê¸°í™”
    if "last_file" not in st.session_state or st.session_state["last_file"] != uploaded_file.name:
        st.session_state.update({"last_file": uploaded_file.name, "messages": [], "analysis_done": False})
        if "retriever" in st.session_state: del st.session_state["retriever"]

    if "retriever" not in st.session_state:
        with st.spinner("RFP ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            retriever, docs = process_pdf(temp_path)
            st.session_state.update({"retriever": retriever, "docs": docs})
            st.session_state["analysis_done"] = True
            st.session_state["messages"].append(AIMessage(content="RFP ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê¸°ë³¸ì •ë³´ ì—‘ì…€ì„ ìƒì„±í•˜ì„¸ìš”."))

    # ì±„íŒ…ì°½ í‘œì‹œ
    for msg in st.session_state["messages"]:
        st.chat_message("user" if isinstance(msg, HumanMessage) else "assistant").write(msg.content)

    # ì—‘ì…€ ìƒì„± ì˜ì—­
    if st.session_state["analysis_done"]:
        st.divider()
        if st.button("ğŸ“ 1. ì‚¬ì—…ê¸°ë³¸ì •ë³´ ì—‘ì…€ ìƒì„±"):
            with st.spinner("ë°ì´í„°ë¥¼ ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘..."):
                data_dict = extract_basic_info_json(st.session_state["docs"])
                
                if data_dict:
                    # ë°ì´í„°í”„ë ˆì„ êµ¬ì„± (í•­ëª© | ë‚´ìš©)
                    df = pd.DataFrame(list(data_dict.items()), columns=['í•­ëª©', 'ë‚´ìš©'])
                    
                    # ì—‘ì…€ íŒŒì¼ ìƒì„±
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df.to_excel(writer, index=False, sheet_name='1. ì‚¬ì—…ê¸°ë³¸ì •ë³´')
                        
                        # ì„œì‹ ì„¤ì •
                        workbook = writer.book
                        worksheet = writer.sheets['1. ì‚¬ì—…ê¸°ë³¸ì •ë³´']
                        header_format = workbook.add_format({'bold': True, 'bg_color': '#D7E4BC', 'border': 1})
                        
                        for col_num, value in enumerate(df.columns.values):
                            worksheet.write(0, col_num, value, header_format)
                        worksheet.set_column(0, 0, 20)
                        worksheet.set_column(1, 1, 60)
                    
                    st.success("ì‚¬ì—…ê¸°ë³¸ì •ë³´ ì¶”ì¶œ ì„±ê³µ!")
                    st.table(df) # í™”ë©´ì— í‘œë¡œ ì¦‰ì‹œ í™•ì¸
                    st.download_button(
                        label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                        data=output.getvalue(),
                        file_name=f"{project_name}_ì‚¬ì—…ê¸°ë³¸ì •ë³´.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                else:
                    st.error("ë°ì´í„° ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    # ì¶”ê°€ ì§ˆì˜ì‘ë‹µ
    if user_input := st.chat_input("RFPì— ëŒ€í•´ ë” ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”."):
        st.chat_message("user").write(user_input)
        st.session_state["messages"].append(HumanMessage(content=user_input))
        with st.chat_message("assistant"):
            ctx = "\n".join([d.page_content for d in st.session_state["retriever"].invoke(user_input)])
            ans = ChatGoogleGenerativeAI(model="gemini-2.0-flash").invoke(f"RFPë‚´ìš©: {ctx}\nì§ˆë¬¸: {user_input}").content
            st.write(ans)
            st.session_state["messages"].append(AIMessage(content=ans))
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")